{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m action \u001b[38;5;241m=\u001b[39m [top_k_actions[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Step the environment\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Render the environment\u001b[39;00m\n",
      "File \u001b[1;32md:\\Faculdade\\MIA\\TSI\\envs.py:168\u001b[0m, in \u001b[0;36mMultiAgentHighwayEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# convert the flat action back to tuple\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     tuple_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_to_tuple(action)\n\u001b[1;32m--> 168\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuple_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_observation(obs), reward, done, truncated, info\n",
      "File \u001b[1;32md:\\anaconda\\envs\\tsi_test5\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:237\u001b[0m, in \u001b[0;36mAbstractEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe road and vehicle must be initialized in the environment implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m     )\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_type\u001b[38;5;241m.\u001b[39mobserve()\n\u001b[0;32m    240\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reward(action)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\tsi_test5\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:277\u001b[0m, in \u001b[0;36mAbstractEnv._simulate\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# Automatically render intermediate simulation steps if a viewer has been launched\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Ignored if the rendering is done offscreen\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    275\u001b[0m         frame \u001b[38;5;241m<\u001b[39m frames \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    276\u001b[0m     ):  \u001b[38;5;66;03m# Last frame will be rendered through env.render() as usual\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_automatic_rendering\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_auto_render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\tsi_test5\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:337\u001b[0m, in \u001b[0;36mAbstractEnv._automatic_rendering\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_video_wrapper\u001b[38;5;241m.\u001b[39mvideo_recorder\u001b[38;5;241m.\u001b[39mcapture_frame()\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\tsi_test5\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:305\u001b[0m, in \u001b[0;36mAbstractEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39mhandle_events()\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 305\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image\u001b[49m()\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_image'"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "from stable_baselines3 import DQN\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from envs import get_sb3_env\n",
    "\n",
    "K = 3  # Number of top actions to display\n",
    "NUM_AGENTS = 3  # Number of agents\n",
    "\n",
    "# Initialize PyGame\n",
    "pygame.init()\n",
    "\n",
    "# Configuration\n",
    "episodes = 10  # Number of episodes to run\n",
    "font_size = 24\n",
    "colors = [\n",
    "    (255, 182, 193), # LANE LEFT\n",
    "    (152, 251, 152), # IDLE\n",
    "    (253, 253, 150), # LANE RIGHT\n",
    "    (216, 191, 216), # FASTER\n",
    "    (173, 216, 230)  # SLOWER\n",
    "]\n",
    "\n",
    "# Load the environment and model\n",
    "env = get_sb3_env(n_agents=NUM_AGENTS, image_obs=False, density=1)\n",
    "model = DQN.load(\"models/DQN/DQN_exp_0.zip\")\n",
    "\n",
    "# Get environment render size\n",
    "rgb_array = env.render()\n",
    "env_render_size = (rgb_array.shape[1], rgb_array.shape[0])  # (Width, Height)\n",
    "\n",
    "# Grid configuration\n",
    "row_height = 100  # Height for each row in the action display\n",
    "row_height_agent = 34  # Height for each row in the action display\n",
    "action_display_height = row_height*K + row_height_agent*(K+1)\n",
    "window_size = (env_render_size[0], env_render_size[1] + action_display_height)\n",
    "\n",
    "# Create a single extended PyGame window\n",
    "screen = pygame.display.set_mode(window_size)\n",
    "pygame.display.set_caption(\"DQN Demonstration\")\n",
    "font = pygame.font.Font(None, font_size)\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Helper function to draw a grid cell\n",
    "def draw_cell(surface, text, color, rect, font):\n",
    "    pygame.draw.rect(surface, color, rect)\n",
    "    pygame.draw.rect(surface, (150, 150, 150), rect, 2)  # Border color\n",
    "    text_surface = font.render(text, True, (0, 0, 0))\n",
    "    surface.blit(text_surface, (rect.x + 10, rect.y + 10))\n",
    "\n",
    "# Main loop for episodes\n",
    "for episode in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Model selects an action\n",
    "        obs_th = torch.as_tensor(obs, device=model.policy.device).unsqueeze(0)\n",
    "        prob_actions_logits = model.policy.q_net(obs_th)\n",
    "        prob_actions = torch.softmax(prob_actions_logits, dim=-1).squeeze().detach().cpu().numpy()\n",
    "        top_k_actions = np.argsort(-prob_actions)[:K]\n",
    "        action = [top_k_actions[0]]\n",
    "\n",
    "        # Step the environment\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Render the environment\n",
    "        rgb_array = env.render()\n",
    "        env_surface = pygame.surfarray.make_surface(np.transpose(rgb_array, (1, 0, 2)))\n",
    "        screen.blit(env_surface, (0, 0))  # Display the environment render\n",
    "\n",
    "        # Display actions in the grid below the environment\n",
    "        start_y = env_render_size[1]\n",
    "        agent_width = env_render_size[0] // NUM_AGENTS\n",
    "\n",
    "        # Header row\n",
    "        for agent_idx in range(NUM_AGENTS):\n",
    "            crashed = \"CRASHED\" if env.original_env.unwrapped.controlled_vehicles[agent_idx].crashed else \"\"\n",
    "            draw_cell(screen, f\"Agent {agent_idx} {crashed}\", (220, 220, 220),\n",
    "                      pygame.Rect(agent_idx * agent_width, start_y, agent_width, row_height_agent), font)\n",
    "        start_y += row_height_agent\n",
    "\n",
    "        # Top K actions\n",
    "        translate_action = {0: 'LANE LEFT', 1: 'IDLE', 2: 'LANE RIGHT', 3: 'FASTER', 4: 'SLOWER'}\n",
    "        \n",
    "        for rank in range(K):\n",
    "            draw_cell(screen, f\"Top {rank + 1}\", (220, 220, 220),\n",
    "                          pygame.Rect(0, start_y, env_render_size[0], row_height_agent), font)\n",
    "            start_y += row_height_agent\n",
    "            \n",
    "            for agent_idx in range(NUM_AGENTS):\n",
    "                action_id = top_k_actions[rank]\n",
    "                action_tuple = env._flat_to_tuple(action_id)\n",
    "                action_name = translate_action[action_tuple[agent_idx].item()]\n",
    "                draw_cell(screen, action_name, colors[action_tuple[agent_idx].item()],\n",
    "                          pygame.Rect(agent_idx * agent_width, start_y, agent_width, row_height), font)\n",
    "            start_y += row_height\n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Manage PyGame events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        clock.tick(30)\n",
    "\n",
    "# Close everything\n",
    "env.close()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m action \u001b[38;5;241m=\u001b[39m [top_k_actions[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Step the environment\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Render the environment\u001b[39;00m\n",
      "File \u001b[1;32md:\\Faculdade\\MIA\\TSI\\envs.py:168\u001b[0m, in \u001b[0;36mMultiAgentHighwayEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# convert the flat action back to tuple\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     tuple_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_to_tuple(action)\n\u001b[1;32m--> 168\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuple_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_observation(obs), reward, done, truncated, info\n",
      "File \u001b[1;32md:\\anaconda\\envs\\tsi_test5\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:237\u001b[0m, in \u001b[0;36mAbstractEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe road and vehicle must be initialized in the environment implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m     )\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_type\u001b[38;5;241m.\u001b[39mobserve()\n\u001b[0;32m    240\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reward(action)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\tsi_test5\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:277\u001b[0m, in \u001b[0;36mAbstractEnv._simulate\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# Automatically render intermediate simulation steps if a viewer has been launched\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Ignored if the rendering is done offscreen\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    275\u001b[0m         frame \u001b[38;5;241m<\u001b[39m frames \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    276\u001b[0m     ):  \u001b[38;5;66;03m# Last frame will be rendered through env.render() as usual\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_automatic_rendering\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_auto_render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\tsi_test5\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:337\u001b[0m, in \u001b[0;36mAbstractEnv._automatic_rendering\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_video_wrapper\u001b[38;5;241m.\u001b[39mvideo_recorder\u001b[38;5;241m.\u001b[39mcapture_frame()\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\tsi_test5\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:305\u001b[0m, in \u001b[0;36mAbstractEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39mhandle_events()\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 305\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image\u001b[49m()\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_image'"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from envs import get_sb3_env\n",
    "\n",
    "K = 3  # Number of top actions to display\n",
    "NUM_AGENTS = 3  # Number of agents\n",
    "\n",
    "# Initialize PyGame\n",
    "pygame.init()\n",
    "\n",
    "# Configuration\n",
    "episodes = 10  # Number of episodes to run\n",
    "font_size = 24\n",
    "colors = [\n",
    "    (255, 182, 193), # LANE LEFT\n",
    "    (152, 251, 152), # IDLE\n",
    "    (253, 253, 150), # LANE RIGHT\n",
    "    (216, 191, 216), # FASTER\n",
    "    (173, 216, 230)  # SLOWER\n",
    "]\n",
    "\n",
    "# Load the environment and model\n",
    "env = get_sb3_env(n_agents=NUM_AGENTS, image_obs=False, density=1)\n",
    "model = PPO.load(\"models/PPO/PPO_exp_6.zip\")\n",
    "\n",
    "# Get environment render size\n",
    "rgb_array = env.render()\n",
    "env_render_size = (rgb_array.shape[1], rgb_array.shape[0])  # (Width, Height)\n",
    "\n",
    "# Grid configuration\n",
    "row_height = 100  # Height for each row in the action display\n",
    "row_height_agent = 34  # Height for each row in the action display\n",
    "action_display_height = row_height*K + row_height_agent*(K+1)\n",
    "window_size = (env_render_size[0], env_render_size[1] + action_display_height)\n",
    "\n",
    "# Create a single extended PyGame window\n",
    "screen = pygame.display.set_mode(window_size)\n",
    "pygame.display.set_caption(\"PPO Demonstration\")\n",
    "font = pygame.font.Font(None, font_size)\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Helper function to draw a grid cell\n",
    "def draw_cell(surface, text, color, rect, font):\n",
    "    pygame.draw.rect(surface, color, rect)\n",
    "    pygame.draw.rect(surface, (150, 150, 150), rect, 2)  # Border color\n",
    "    text_surface = font.render(text, True, (0, 0, 0))\n",
    "    surface.blit(text_surface, (rect.x + 10, rect.y + 10))\n",
    "\n",
    "# Main loop for episodes\n",
    "for episode in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Model selects an action\n",
    "        obs_th = torch.as_tensor(obs, device=model.policy.device).unsqueeze(0)\n",
    "        prob_actions_logits = model.policy.get_distribution(obs_th).distribution.logits\n",
    "        prob_actions = torch.softmax(prob_actions_logits, dim=-1).squeeze().detach().cpu().numpy()\n",
    "        top_k_actions = np.argsort(-prob_actions)[:K]\n",
    "        action = [top_k_actions[0]]\n",
    "\n",
    "        # Step the environment\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Render the environment\n",
    "        rgb_array = env.render()\n",
    "        env_surface = pygame.surfarray.make_surface(np.transpose(rgb_array, (1, 0, 2)))\n",
    "        screen.blit(env_surface, (0, 0))  # Display the environment render\n",
    "\n",
    "        # Display actions in the grid below the environment\n",
    "        start_y = env_render_size[1]\n",
    "        agent_width = env_render_size[0] // NUM_AGENTS\n",
    "\n",
    "        # Header row\n",
    "        for agent_idx in range(NUM_AGENTS):\n",
    "            crashed = \"CRASHED\" if env.original_env.unwrapped.controlled_vehicles[agent_idx].crashed else \"\"\n",
    "            draw_cell(screen, f\"Agent {agent_idx} {crashed}\", (220, 220, 220),\n",
    "                      pygame.Rect(agent_idx * agent_width, start_y, agent_width, row_height_agent), font)\n",
    "        start_y += row_height_agent\n",
    "\n",
    "        # Top K actions\n",
    "        translate_action = {0: 'LANE LEFT', 1: 'IDLE', 2: 'LANE RIGHT', 3: 'FASTER', 4: 'SLOWER'}\n",
    "        \n",
    "        for rank in range(K):\n",
    "            draw_cell(screen, f\"Top {rank + 1}\", (220, 220, 220),\n",
    "                          pygame.Rect(0, start_y, env_render_size[0], row_height_agent), font)\n",
    "            start_y += row_height_agent\n",
    "            \n",
    "            for agent_idx in range(NUM_AGENTS):\n",
    "                action_id = top_k_actions[rank]\n",
    "                action_tuple = env._flat_to_tuple(action_id)\n",
    "                action_name = translate_action[action_tuple[agent_idx].item()]\n",
    "                draw_cell(screen, action_name, colors[action_tuple[agent_idx].item()],\n",
    "                          pygame.Rect(agent_idx * agent_width, start_y, agent_width, row_height), font)\n",
    "            start_y += row_height\n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Manage PyGame events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        clock.tick(30)\n",
    "\n",
    "# Close everything\n",
    "env.close()\n",
    "pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
